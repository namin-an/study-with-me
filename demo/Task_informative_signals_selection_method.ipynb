{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 511.7 MB 19 kB/s s eta 0:00:01   |█▏                              | 18.3 MB 8.7 MB/s eta 0:00:57     |███████████████                 | 240.5 MB 58.3 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 77.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.19.4)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 77.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 74.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.0)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 39.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 5.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 4.0 MB/s  eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.21.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.6.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.43.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 107.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 3.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow) (3.0.7)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=82e2df3200b1ec3d19d5b2bfef734b45127ee3abd5cb978948b69cf4cf90e9ec\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built termcolor\n",
      "Installing collected packages: wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-pasta-0.2.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 opt-einsum-3.3.0 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 wrapt-1.14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import APIs\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Control GPU consumption\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/opt/pytorch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mne/io/edf/edf.py:1047: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/opt/pytorch/dataloaders/bci_comp42a.py:57: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_gdf(file_names, preload=True, eog=['EOG-left', 'EOG-central', 'EOG-right'], verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 288 events and 385 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/mne/io/edf/edf.py:1047: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
      "/opt/pytorch/dataloaders/bci_comp42a.py:57: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_gdf(file_names, preload=True, eog=['EOG-left', 'EOG-central', 'EOG-right'], verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '783']\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 288 events and 385 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "import dataloaders\n",
    "from dataloaders.bci_comp42a import BCIComp42aDataLoader\n",
    "\n",
    "train_dataset = BCIComp42aDataLoader(data_path='/opt/pytorch/datasets/BCIComp42a',\n",
    "                                     label_path='/opt/pytorch/datasets/BCIComp42a/true_labels',\n",
    "                                     is_test=False,\n",
    "                                     target_subject = 0, # subject #0 ~ #8\n",
    "                                     s_freq=128, # 250 Hz -> 128 Hz\n",
    "                                     l_freq=0, h_freq=38,\n",
    "                                     t_min=-0.5, t_max=2.5)\n",
    "\n",
    "test_dataset = BCIComp42aDataLoader(data_path='/opt/pytorch/datasets/BCIComp42a',\n",
    "                                    label_path='/opt/pytorch/datasets/BCIComp42a/true_labels',\n",
    "                                    is_test=True,\n",
    "                                    target_subject = 0, # subject #0 ~ #8\n",
    "                                    s_freq=128, # 250 Hz -> 128 Hz\n",
    "                                    l_freq=0, h_freq=38,\n",
    "                                    t_min=-0.5, t_max=2.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 22, 385, 1) (288, 22, 385, 1)\n",
      "(288,) (288,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "assert len(train_dataset) == len(test_dataset)\n",
    "\n",
    "train_X = np.empty(shape=(len(train_dataset), train_dataset[0]['features'].shape[1], train_dataset[0]['features'].shape[2]),\n",
    "                   dtype='float64')\n",
    "train_y = np.empty(shape=(len(train_dataset)), dtype='int64')\n",
    "\n",
    "test_X = np.empty(shape=(len(train_dataset), train_dataset[0]['features'].shape[1], train_dataset[0]['features'].shape[2]),\n",
    "                  dtype='float64')\n",
    "test_y = np.empty(shape=(len(train_dataset)), dtype='int64')\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    train_X[i] = train_dataset[i]['features']\n",
    "    train_y[i] = train_dataset[i]['labels']\n",
    "    \n",
    "    test_X[i] = test_dataset[i]['features']\n",
    "    test_y[i] = test_dataset[i]['labels']\n",
    "\n",
    "train_X = np.expand_dims(train_X, axis=-1)\n",
    "test_X = np.expand_dims(test_X, axis=-1)\n",
    "\n",
    "num = np.unique(train_y, axis=0)\n",
    "num = num.shape[0]\n",
    "\n",
    "train_Y = np.eye(num)[train_y]\n",
    "test_Y = np.eye(num)[test_y]\n",
    "\n",
    "print(train_X.shape, test_X.shape) # (# trials, C, T, 1)\n",
    "print(train_y.shape, test_y.shape) # (# trials, # classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load dataset\n",
    "# # I exploited Lee et al.'s, GigaScience, 2019.\n",
    "# # The entire dataset is available at \"https://github.com/namin-an/RL_BCI.git369.\"\n",
    "# # path = 'Define/Your/Own/Path'\n",
    "# train_X, train_Y = np.load(path + \"train.npy\"), np.load(path + \"trlbl.npy\")\n",
    "# test_X, test_Y = np.load(path + \"test.npy\"), np.load(path + \"tslbl.npy\")\n",
    "\n",
    "# # To check the size of data and label (C: # electrodes, T: # timepoints).\n",
    "# print(train_X.shape, test_X.shape) # (C, T, # trials)\n",
    "# print(train_Y.shape, test_Y.shape) # (# classes, # trials)\n",
    "\n",
    "# # Select electrode channels on the sensorymotor area.\n",
    "# ch_list = [7, 32, 8, 9, 33, 10, 34, 12, 35, 13, 36, 14, 37, 17, 38, 18, 39, 19, 40, 20]\n",
    "# # We already conducted BPF (8~30Hz) and segments (0.5~3.5 sec).\n",
    "# # Segments from 1 to 3.5-second (We used preprocessed data).\n",
    "# train_X, test_X = train_X[ch_list, 500:, :], test_X[ch_list, 500:, :]\n",
    "# # Downsample to 100Hz sampling rate.\n",
    "# train_X = resample(train_X, int(train_X.shape[1] * 0.1), axis=1)\n",
    "# test_X = resample(test_X, int(test_X.shape[1] * 0.1), axis=1)\n",
    "\n",
    "# # Reshape the data.\n",
    "# train_X = np.expand_dims(np.moveaxis(train_X, -1, 0), -1)\n",
    "# test_X = np.expand_dims(np.moveaxis(test_X, -1, 0), -1)\n",
    "# train_Y, test_Y = np.swapaxes(train_Y, 0, 1), np.swapaxes(test_Y, 0, 1)\n",
    "# # To check the size.\n",
    "# print(train_X.shape, test_X.shape) # (# trials, C, T, 1)\n",
    "# print(train_Y.shape, test_Y.shape) # (# trials, # classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a deep neural network-based BCI model.\n",
    "# Here, we used Ko et al.'s, arXiv, 2020 (MSNN).\n",
    "# For detail, see \"https://arxiv.org/abs/2003.02657.\"\n",
    "class MSNN(tf.keras.Model):\n",
    "    tf.keras.backend.set_floatx(\"float64\")\n",
    "    def __init__(self):\n",
    "        super(MSNN, self).__init__()\n",
    "        self.C = 20\n",
    "        self.fs = 100\n",
    "\n",
    "        # Regularizer\n",
    "        self.regularizer = tf.keras.regularizers.L1L2(l1=.001, l2=.01)\n",
    "\n",
    "        # Activation functions\n",
    "        self.activation = tf.keras.layers.LeakyReLU()\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "        # Define convolutions\n",
    "        conv = lambda D, kernel : tf.keras.layers.Conv2D(D, kernel, kernel_regularizer=self.regularizer)\n",
    "        sepconv = lambda D, kernel : tf.keras.layers.SeparableConv2D(D, kernel, padding=\"same\",\n",
    "                                                                    depthwise_regularizer=self.regularizer,\n",
    "                                                                    pointwise_regularizer=self.regularizer)\n",
    "        \n",
    "        # Spectral convoltuion\n",
    "        self.conv0 = conv(4, (1, int(self.fs/2)))\n",
    "        \n",
    "        # Spatio-temporal convolution\n",
    "        self.conv1t = sepconv(16, (1, 25))\n",
    "        self.conv1s = conv(16, (self.C, 1))\n",
    "        \n",
    "        self.conv2t = sepconv(32, (1, 15))\n",
    "        self.conv2s = conv(32, (self.C, 1))\n",
    "        \n",
    "        self.conv3t = sepconv(64, (1, 6))\n",
    "        self.conv3s = conv(64, (self.C, 1))\n",
    "\n",
    "        # Flatteninig\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "        # Decision making\n",
    "        class_num = 4 # 2\n",
    "        self.dense = tf.keras.layers.Dense(class_num, activation=None, kernel_regularizer=self.regularizer)\n",
    "\n",
    "    def embedding(self, x, random_mask=False):\n",
    "        x = self.activation(self.conv0(x))\n",
    "\n",
    "        x = self.activation(self.conv1t(x))\n",
    "        f1 = self.activation(self.conv1s(x))\n",
    "\n",
    "        x = self.activation(self.conv2t(x))\n",
    "        f2 = self.activation(self.conv2s(x))\n",
    "\n",
    "        x = self.activation(self.conv3t(x))\n",
    "        f3 = self.activation(self.conv3s(x))\n",
    "\n",
    "        feature = tf.concat((f1, f2, f3), -1)\n",
    "        return feature\n",
    "\n",
    "    def classifier(self, feature):\n",
    "        # Flattening, dropout, mapping into the decision nodes\n",
    "        feature = self.flatten(feature)\n",
    "        feature = self.dropout(feature)\n",
    "        y_hat = self.softmax(self.dense(feature))\n",
    "        return y_hat\n",
    "\n",
    "    def GAP(self, feature):\n",
    "        return tf.reduce_mean(feature, -2)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Extract feature using MSNN encoder\n",
    "        feature = self.embedding(x)\n",
    "        # Global Average Pooling\n",
    "        feature = self.GAP(feature)\n",
    "        # Decision making\n",
    "        y_hat = self.classifier(feature)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the informative segments selection agent module.\n",
    "# Define actor network (for categorical actions: selection/rejection)\n",
    "class ACTOR(tf.keras.Model):\n",
    "    def __init__(self, n_actions=2):\n",
    "        super().__init__()\n",
    "        self.actor = tf.keras.layers.Dense(n_actions, activation=None, \n",
    "                                          kernel_regularizer=tf.keras.regularizers.L1L2(l1=.001, l2=.01))        \n",
    "    def call(self, segment):\n",
    "        return self.actor(segment) # Outputs logit vector.\n",
    "    \n",
    "# Define critic network\n",
    "class CRITIC(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.critic = tf.keras.layers.Dense(1, activation=None,\n",
    "                                           kernel_regularizer=tf.keras.regularizers.L1L2(l1=.001, l2=.01))\n",
    "    def call(self, segment):\n",
    "        return tf.keras.activations.sigmoid(self.critic(segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define utility functions.\n",
    "def gradient(model, inputs, labels, mask=None):\n",
    "    with tf.GradientTape() as tape:\n",
    "        if mask is None:\n",
    "            yhat = model(inputs)\n",
    "        else:\n",
    "            feature = model.GAP(model.embedding(inputs) * mask)\n",
    "            yhat = model.classifier(feature)\n",
    "        \n",
    "        loss = tf.keras.losses.binary_crossentropy(labels, yhat)\n",
    "\n",
    "    grad = tape.gradient(loss, model.trainable_variables)\n",
    "    return loss, grad\n",
    "\n",
    "def agent_gradient(model, actor, critic, inputs, feature, labels, state, state_next):\n",
    "    gamma = 0.95 # discount factor\n",
    "    with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "        loss_FM = tf.keras.losses.binary_crossentropy(labels, model(inputs))      \n",
    "        loss_AM = tf.keras.losses.binary_crossentropy(labels, model.classifier(feature))\n",
    "\n",
    "        # Reward, r_t\n",
    "        reward = loss_FM - loss_AM\n",
    "        # Advantage, A_t\n",
    "        advantage = reward[:, None] + gamma * critic(state_next) - critic(state)            \n",
    "        # Critic loss\n",
    "        critic_loss = 0.5 * tf.math.square(advantage)            \n",
    "        # Actor loss\n",
    "        actor_loss = -tf.math.log(tf.nn.softmax(actor(state))) * advantage\n",
    "\n",
    "    critic_grad = tape1.gradient(critic_loss, critic.trainable_variables)\n",
    "    actor_grad = tape2.gradient(actor_loss, actor.trainable_variables)\n",
    "    \n",
    "    qvalue = actor(state)\n",
    "    qvalue = tf.reduce_max(qvalue, axis=[1])\n",
    "    \n",
    "    return critic_loss, critic_grad, actor_loss, actor_grad, reward, qvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define experiment conducting class.\n",
    "# Here, we trained and tested MSNN without the proposed agent module.\n",
    "class experiment():\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y):\n",
    "        # Load dataset.\n",
    "        # For simplicity, we just removed validating phase here.\n",
    "        self.Xtr, self.Ytr = train_X, train_Y\n",
    "        self.Xts, self.Yts = test_X, test_Y\n",
    "        self.Yts = np.argmax(self.Yts, axis=-1) # To use scikit-learn accuracy function\n",
    "        \n",
    "        # Randomize the training dataset.\n",
    "        rand_idx = np.random.permutation(self.Xtr.shape[0])\n",
    "        self.Xtr, self.Ytr = self.Xtr[rand_idx, :, :, :], self.Ytr[rand_idx, :]\n",
    "\n",
    "        # Learning schedules\n",
    "        self.init_LR = 1e-3\n",
    "        self.num_epochs_pre = 10 # Pre-training epochs\n",
    "        self.num_epochs = 30\n",
    "        self.num_batch = 20\n",
    "        self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=self.init_LR)\n",
    "        \n",
    "        # Here, we used subject 1's 2nd session data.\n",
    "        self.sbj_idx, self.sess_idx = 1, 2\n",
    "        print(f\"START TRAINING Subject {self.sbj_idx}, Session {self.sess_idx}\")\n",
    "        \n",
    "        # Call optimizer.\n",
    "        self.num_batch_iter = int(self.Xtr.shape[0]/self.num_batch)\n",
    "        \n",
    "    def training_FM(self):\n",
    "        # Call MSNN.\n",
    "        msnn = MSNN()\n",
    "        \n",
    "        # To record the loss curve.\n",
    "        loss_FM = []\n",
    "        for epoch in range(self.num_epochs):\n",
    "            loss_per_epoch = 0\n",
    "\n",
    "            for batch in range(self.num_batch_iter):\n",
    "                # Sample minibatch.\n",
    "                xb = self.Xtr[batch * self.num_batch : (batch + 1) * self.num_batch, :, :, :]\n",
    "                yb = self.Ytr[batch * self.num_batch : (batch + 1) * self.num_batch, :]\n",
    "\n",
    "                # Estimate loss\n",
    "                loss, grads = gradient(msnn, xb, yb)\n",
    "\n",
    "                # Update the parameters\n",
    "                self.optimizer.apply_gradients(zip(grads, msnn.trainable_variables))\n",
    "#                 loss_FM.append(np.mean(loss))\n",
    "                loss_per_epoch += np.mean(loss)\n",
    "\n",
    "            loss_per_epoch /= self.num_batch_iter\n",
    "            loss_FM.append(loss_per_epoch)\n",
    "            \n",
    "            # Reporting\n",
    "            print(f\"Iteration {epoch + 1}, Training Loss {loss_per_epoch:>.04f}\")\n",
    "            \n",
    "        # Test the learned model.\n",
    "        Yts_hat = np.argmax(msnn(test_X), axis=-1)\n",
    "        print(f\"\\nSubject {self.sbj_idx}, Session {self.sess_idx},\\\n",
    "        Testing accuracy: {accuracy_score(self.Yts, Yts_hat)}!\\n\")\n",
    "        return loss_FM\n",
    "    \n",
    "    def training_AM(self):\n",
    "        # Call MSNN.\n",
    "        msnn = MSNN()\n",
    "        \n",
    "        # To record the loss curve.\n",
    "        loss_AM = []\n",
    "        # Pre-training without the agent module\n",
    "        for epoch in range(self.num_epochs_pre):\n",
    "            loss_per_epoch = 0\n",
    "\n",
    "            for batch in range(self.num_batch_iter):\n",
    "                # Sample minibatch.\n",
    "                xb = self.Xtr[batch * self.num_batch : (batch + 1) * self.num_batch, :, :, :]\n",
    "                yb = self.Ytr[batch * self.num_batch : (batch + 1) * self.num_batch, :]\n",
    "\n",
    "                # Estimate loss\n",
    "                loss, grads = gradient(msnn, xb, yb)\n",
    "\n",
    "                # Update the parameters\n",
    "                self.optimizer.apply_gradients(zip(grads, msnn.trainable_variables))\n",
    "                loss_AM.append(np.mean(loss))\n",
    "                loss_per_epoch += np.mean(loss)\n",
    "\n",
    "            loss_per_epoch /= self.num_batch_iter\n",
    "\n",
    "            # Reporting\n",
    "            print(f\"Iteration {epoch + 1}, Training Loss {loss_per_epoch:>.04f}\")\n",
    "            \n",
    "        # Call agent module.\n",
    "        actor = ACTOR()\n",
    "        critic = CRITIC()\n",
    "        \n",
    "        critic_loss_list, actor_loss_list = [], []\n",
    "        reward_list, qvalue_list = [], []\n",
    "        # Training with the agent module\n",
    "        for epoch in range(self.num_epochs - self.num_epochs_pre):\n",
    "            loss_per_epoch = 0\n",
    "            critic_loss_per_epoch, actor_loss_per_epoch = 0, 0\n",
    "            reward_per_epoch, qvalue_per_epoch = 0, 0\n",
    "            \n",
    "            for batch in range(self.num_batch_iter):\n",
    "                print(f'EPOCH: {epoch}/{self.num_epochs - self.num_epochs_pre} BATCH: {batch}/{self.num_batch_iter}')\n",
    "                # Sample minibatch.\n",
    "                xb = self.Xtr[batch * self.num_batch : (batch + 1) * self.num_batch, :, :, :]\n",
    "                yb = self.Ytr[batch * self.num_batch : (batch + 1) * self.num_batch, :]\n",
    "                \n",
    "                # Extract full segments.\n",
    "                features = msnn.embedding(xb)\n",
    "                              \n",
    "                agg_wo_current = np.zeros((self.num_batch, features.shape[-1]))\n",
    "                num_added = np.zeros((self.num_batch, features.shape[-1])) # To estimate the denominator.\n",
    "                mask = np.zeros(features.shape) # Mask generated by the agent module\n",
    "                for t in range(features.shape[-2] - 1): # t = 1,...,T'\n",
    "                    deno1 = np.copy(num_added)\n",
    "                    deno2 = np.copy(num_added) + 1 # For the features with the current segment.\n",
    "                    # To avoid zero-division.\n",
    "                    deno1[deno1 == 0] = 1.\n",
    "                    \n",
    "                    agg_w_current = agg_wo_current + features[:, 0, t, :]\n",
    "                    \n",
    "                    # Define state, s_t.\n",
    "                    state = np.concatenate((agg_wo_current/deno1, agg_w_current/deno2), axis=-1)\n",
    "                    # Get action, a_t.\n",
    "                    action_probs = actor(state) \n",
    "                    action = np.tile(tf.random.categorical(action_probs, 1).numpy(), 112) # (5, 112)\n",
    "                    mask[:, 0, t, :] = action\n",
    "                    num_added += action\n",
    "                    \n",
    "                    # Current feature after action decision, phi_t.\n",
    "                    deno3 = np.copy(num_added)\n",
    "                    deno3[deno3 == 0] = 1 # To avoid zero-division.\n",
    "                    feature = (agg_wo_current + features[:, 0, t, :] * action)/deno3\n",
    "                    \n",
    "                    # Define next state, s_{t+1}, temporally.\n",
    "                    agg_wo_current = feature\n",
    "                    tmp = agg_wo_current + features[:, 0, t + 1, :]\n",
    "                    \n",
    "                    state_next = np.concatenate((agg_wo_current/deno3, tmp/(deno3 + 1)), axis=-1)\n",
    "                    \n",
    "                    # Calculate critic and actor loss values\n",
    "                    feature = np.expand_dims(feature, axis=1)\n",
    "                    feature = np.concatenate((feature, feature, feature), axis=1)\n",
    "                    critic_loss, critic_grads, actor_loss, actor_grads, reward, qvalue =\\\n",
    "                    agent_gradient(msnn, actor, critic, xb, feature, yb, state, state_next)\n",
    "                    \n",
    "                    critic_loss_per_epoch += np.mean(critic_loss)\n",
    "                    actor_loss_per_epoch += np.mean(actor_loss)\n",
    "                    reward_per_epoch += np.mean(reward)\n",
    "                    qvalue_per_epoch += np.mean(qvalue)\n",
    "                    \n",
    "                    self.optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
    "                    self.optimizer.apply_gradients(zip(actor_grads, actor.trainable_variables))\n",
    "                                        \n",
    "                # Finally, predict labels of input EEG using the selected segments.                \n",
    "                # Update the parameters\n",
    "                loss, grads = gradient(msnn, xb, yb, mask)\n",
    "                self.optimizer.apply_gradients(zip(grads, msnn.trainable_variables))\n",
    "\n",
    "                loss_per_epoch += np.mean(loss)                              \n",
    "\n",
    "            loss_per_epoch /= self.num_batch_iter\n",
    "            critic_loss_per_epoch /= (self.num_batch_iter*(features.shape[-2] - 1))\n",
    "            actor_loss_per_epoch /= (self.num_batch_iter*(features.shape[-2] - 1))\n",
    "            reward_per_epoch /= (self.num_batch_iter*(features.shape[-2] - 1))\n",
    "            qvalue_per_epoch /= (self.num_batch_iter*(features.shape[-2] - 1))\n",
    "            \n",
    "            loss_AM.append(loss_per_epoch)\n",
    "            critic_loss_list.append(critic_loss_per_epoch) \n",
    "            actor_loss_list.append(actor_loss_per_epoch)\n",
    "            reward_list.append(reward_per_epoch) \n",
    "            qvalue_list.append(qvalue_per_epoch)\n",
    "            \n",
    "            plt.plot(np.arange(len(critic_loss_list)), np.array(critic_loss_list))\n",
    "            plt.show()\n",
    "            plt.plot(np.arange(len(actor_loss_list)), np.array(actor_loss_list))\n",
    "            plt.show()\n",
    "            plt.plot(np.arange(len(reward_list)), np.array(reward_list))\n",
    "            plt.show()\n",
    "            plt.plot(np.arange(len(qvalue_list)), np.array(qvalue_list))\n",
    "            plt.show()\n",
    "            \n",
    "            # Reporting\n",
    "            print(f\"Iteration {epoch + 1 + self.num_epochs_pre}, Training Loss {loss_per_epoch:>.04f}\")\n",
    "            \n",
    "        # Test the learned model.\n",
    "        Yts_hat = np.argmax(msnn(test_X), axis=-1)\n",
    "        print(f\"\\nSubject {self.sbj_idx}, Session {self.sess_idx}, \\\n",
    "        Testing accuracy: {accuracy_score(self.Yts, Yts_hat)}!\\n\")\n",
    "        return loss_AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING Subject 1, Session 2\n"
     ]
    }
   ],
   "source": [
    "exp = experiment(train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Training Loss 0.5656\n",
      "Iteration 2, Training Loss 0.5633\n",
      "Iteration 3, Training Loss 0.5630\n",
      "Iteration 4, Training Loss 0.5625\n",
      "Iteration 5, Training Loss 0.5603\n",
      "Iteration 6, Training Loss 0.5530\n",
      "Iteration 7, Training Loss 0.5376\n",
      "Iteration 8, Training Loss 0.5170\n",
      "Iteration 9, Training Loss 0.4968\n",
      "Iteration 10, Training Loss 0.4794\n",
      "Iteration 11, Training Loss 0.4650\n",
      "Iteration 12, Training Loss 0.4534\n",
      "Iteration 13, Training Loss 0.4439\n",
      "Iteration 14, Training Loss 0.4361\n",
      "Iteration 15, Training Loss 0.4294\n",
      "Iteration 16, Training Loss 0.4234\n",
      "Iteration 17, Training Loss 0.4178\n",
      "Iteration 18, Training Loss 0.4125\n",
      "Iteration 19, Training Loss 0.4073\n",
      "Iteration 20, Training Loss 0.4023\n",
      "Iteration 21, Training Loss 0.3973\n",
      "Iteration 22, Training Loss 0.3923\n",
      "Iteration 23, Training Loss 0.3874\n",
      "Iteration 24, Training Loss 0.3827\n",
      "Iteration 25, Training Loss 0.3782\n",
      "Iteration 26, Training Loss 0.3736\n",
      "Iteration 27, Training Loss 0.3693\n",
      "Iteration 28, Training Loss 0.3650\n",
      "Iteration 29, Training Loss 0.3608\n",
      "Iteration 30, Training Loss 0.3567\n",
      "\n",
      "Subject 1, Session 2,        Testing accuracy: 0.5659722222222222!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_FM = exp.training_FM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(loss_FM))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Training Loss 0.5637\n"
     ]
    }
   ],
   "source": [
    "loss_AM = exp.training_AM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(loss_AM))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
